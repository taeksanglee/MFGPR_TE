{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe use and edit the original code from https://github.com/paraklas/NARGP\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "We use and edit the original code from https://github.com/paraklas/NARGP\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fAf5WhptZznu"
   },
   "outputs": [],
   "source": [
    "#!pip install GPy\n",
    "import GPy\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.mlab as ml\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy.matlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select expander protocol\n",
    "idx_prcl = 0\n",
    "protocols = ['AnteFace30x60mm38cc','AnteScalp50x130mm243cc','Forehead30x60mm38cc',\\\n",
    "            'LeftClav50x100mm133cc','LowerFace30x60mm38cc','PostScalp60x120mm221cc']\n",
    "protocol = protocols[idx_prcl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 3 # input dataset dimension\n",
    "##### traing input dataset\n",
    "Nts = 400\n",
    "\n",
    "set_tpts = [np.array([0,7,21,35,42,49,56,63,70,77,84,91,98,105]),\\\n",
    "            np.array([0,7,21,35,42,49,56,63,70,77,84,91,98,105]),\\\n",
    "            np.array([0,7,21,35,42,49,56,63,70,77,84,91,98,105]),\\\n",
    "            np.array([0,7,14,21,28,35,42,49,56,70,91,105]),\\\n",
    "            np.array([0,7,14,21,28,35,42,49,56,63,70,105]),\\\n",
    "            np.array([0,7,21,35,42,49,56,63,70,77,84,91,98,105])]\n",
    "\n",
    "tpts = set_tpts[idx_prcl]\n",
    "\n",
    "n_tpts = np.array([14,14,14,12,12,14])\n",
    "\n",
    "if idx_prcl == 3 or idx_prcl == 4:\n",
    "    idx_low = np.array([0,20,40,60,80,100,120,140,160,180,200,220,240,260,280,300,320,340,360,380,400,406,412,418,424,432,439])\n",
    "    idx_low = np.array([0,10,20,30,40,50,60,70,80,90,100,\\\n",
    "                        110,120,130,140,150,160,170,180,190,200,\\\n",
    "                        210,220,230,240,250,260,270,280,290,300,\\\n",
    "                        310,320,330,340,350,360,370,380,390,400,\\\n",
    "                        410,420,430,439])\n",
    "else:\n",
    "    idx_low = np.array([0,20,40,60,80,100,120,140,160,180,200,220,240,260,280,300,320,340,360,380,400,420,440,460,480,500,519])\n",
    "    idx_low = np.array([0,10,20,30,40,50,60,70,80,90,100,\\\n",
    "                        110,120,130,140,150,160,170,180,190,200,\\\n",
    "                        210,220,230,240,250,260,270,280,290,300,\\\n",
    "                        310,320,330,340,350,360,370,380,390,400,\\\n",
    "                        410,420,430,440,450,460,470,480,490,500,510,519])\n",
    "    \n",
    "tpts_LF = np.loadtxt('LowFidelityModel/time_vec_%s.txt'%protocol)[idx_low]\n",
    "tpts_HF = tpts\n",
    "\n",
    "'''Training input dataset of low fidelity'''\n",
    "training_data1 = np.loadtxt('LowFidelityModel/growth_low_fidelity_200T.txt')[50:,:]\n",
    "xdim1,ydim1 = np.shape(training_data1)\n",
    "num_time1 = np.shape(tpts_LF)[0]\n",
    "X1 = np.zeros((xdim1*num_time1,ydim1+1))\n",
    "for ii in range(xdim1):\n",
    "    X1[num_time1*ii:num_time1*(ii+1),:] = np.hstack([np.matlib.repmat(training_data1[ii,:],num_time1,1),tpts_LF[:,None]])\n",
    "\n",
    "'''Training input dataset of highest fidelity'''\n",
    "training_data2 = np.loadtxt('HighFidelityModel/growth_high_fidelity_100T.txt')\n",
    "xdim2, ydim2 = np.shape(training_data2)\n",
    "num_time2 = np.shape(tpts_HF)[0]\n",
    "X2 = np.zeros((xdim2*num_time2,ydim2+1))\n",
    "for ii in range(xdim2):\n",
    "    X2[num_time2*ii:num_time2*(ii+1),:] = np.hstack([np.matlib.repmat(training_data2[ii,:],num_time2,1),tpts_HF[:,None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation index, select one value between 0~49\n",
    "val_idx = 41\n",
    "val_high = np.loadtxt('HighFidelityValidation/growth_50T_validation.txt')\n",
    "val_high = val_high[val_idx,:]\n",
    "val_high_Y = np.loadtxt('HighFidelityValidation/thg_mid_%s.txt'%protocol,delimiter=',')[val_idx,tpts_HF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "Xtest = np.hstack([np.matlib.repmat(val_high,Nts,1),np.linspace(0,105, Nts)[:,None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low fidelity validation dataset\n",
    "val_low = np.loadtxt('LowFidelityValidation/growth_50T_validation.txt')\n",
    "val_low = val_low[val_idx,:]\n",
    "val_low_Y = np.loadtxt('LowFidelityValidation/thetaG_LF_%s.txt'%protocol)[val_idx,idx_low]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Training output dataset at low fidelity'''\n",
    "Y1 = np.loadtxt('LowFidelityModel/thetaG_LF_%s.txt'%protocol)[:,idx_low]\n",
    "Y1 = Y1.flatten()\n",
    "Y1 = Y1[:,None]\n",
    "\n",
    "'''Training output dataset at high fidelity'''\n",
    "Y2 = np.loadtxt('HighFidelityModel/thg_mid_%s.txt'%protocol,delimiter=',')[:,tpts_HF]\n",
    "Y2 = Y2.flatten()\n",
    "Y2 = Y2[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Optimized model1:\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -28686.407409900596\n",
      "Number of Parameters : 5\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                  value  |  constraints  |  priors\n",
      "  \u001b[1mrbf.variance           \u001b[0;0m  |     0.7472134655012799  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale        \u001b[0;0m  |                   (3,)  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  8.314815921762525e-05  |   +ve fixed   |        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reconstraining parameters GP_regression.Gaussian_noise.variance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization restart 1/5, f = -29591.087266067727\n"
     ]
    }
   ],
   "source": [
    "X_m = np.mean(X1, axis=0)\n",
    "X_s = np.std(X1, axis=0)\n",
    "X1_scaled = (X1 - X_m) / X_s\n",
    "X2_scaled = (X2 - X_m) / X_s\n",
    "Xtest_scaled = (Xtest - X_m) / X_s\n",
    "\n",
    "active_dimensions = np.arange(0,dim)\n",
    "\n",
    "''' Train level 1 '''\n",
    "k1 = GPy.kern.RBF(dim, ARD=True)\n",
    "m1 = GPy.models.GPRegression(X=X1_scaled, Y=Y1, kernel=k1)\n",
    "m1[\".*Gaussian_noise\"] = m1.Y.var()*0.001\n",
    "m1[\".*Gaussian_noise\"].fix()\n",
    "\n",
    "m1.optimize(max_iters = 500)\n",
    "print('*' * 80)\n",
    "print('Optimized model1:')\n",
    "print(m1)\n",
    "\n",
    "m1[\".*Gaussian_noise\"].unfix()\n",
    "m1[\".*Gaussian_noise\"].constrain_positive()\n",
    "m1.optimize_restarts(5, optimizer = \"bfgs\",  max_iters = 1000)\n",
    "\n",
    "Xp = X2_scaled\n",
    "mu1, v1 = m1.predict(Xp)\n",
    "print('Finish train low fidelity model')\n",
    "\n",
    "''' Train level 2 '''\n",
    "XX2 = np.hstack((X2_scaled, mu1))\n",
    "\n",
    "k2 = GPy.kern.RBF(1, active_dims = [dim])*GPy.kern.RBF(dim, active_dims = active_dimensions, ARD = True) \\\n",
    "    + GPy.kern.RBF(dim, active_dims = active_dimensions, ARD = True)\n",
    "\n",
    "m2 = GPy.models.GPRegression(X=XX2, Y=Y2, kernel=k2)\n",
    "m2[\".*Gaussian_noise\"] = m2.Y.var()*0.001\n",
    "m2[\".*Gaussian_noise\"].fix()\n",
    "\n",
    "m2.optimize(max_iters = 500)\n",
    "print('*' * 80)\n",
    "print('Optimized model2:')\n",
    "print(m2)\n",
    "\n",
    "m2[\".*Gaussian_noise\"].unfix()\n",
    "m2[\".*Gaussian_noise\"].constrain_positive()\n",
    "m2.optimize_restarts(5, optimizer = \"bfgs\",  max_iters = 1000)\n",
    "print('Finish train level multi-fidelity model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Predict at test points #\n",
    "########################## \n",
    "\n",
    "nsamples = 1000\n",
    "mu1, C1 = m1.predict(Xtest_scaled, full_cov=True)\n",
    "_, var1 = m1.predict(Xtest_scaled)\n",
    "\n",
    "Z = np.random.multivariate_normal(mu1.flatten(),C1,nsamples)\n",
    "\n",
    "tmp_m = np.zeros((nsamples,Nts))\n",
    "tmp_v = np.zeros((nsamples,Nts))\n",
    "for i in range(nsamples):\n",
    "    mu, v = m2.predict(np.hstack((Xtest_scaled, Z[i,:][:,None])))\n",
    "    tmp_m[i,:] = mu.flatten()\n",
    "    tmp_v[i,:] = v.flatten()\n",
    "\n",
    "# get posterior mean and variance\n",
    "mean = np.mean(tmp_m, axis = 0)[:,None]\n",
    "var = np.mean(tmp_v, axis = 0)[:,None]+ np.var(tmp_m, axis = 0)[:,None]\n",
    "var = np.abs(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Low fidelity model only '''\n",
    "k4 = GPy.kern.RBF(dim, ARD=True)\n",
    "m4 = GPy.models.GPRegression(X=X1_scaled, Y=Y1, kernel=k4)\n",
    "m4[\".*Gaussian_noise\"] = m4.Y.var()*0.001\n",
    "m4[\".*Gaussian_noise\"].fix()\n",
    "\n",
    "m4.optimize(max_iters = 500)\n",
    "print('*' * 80)\n",
    "print('Optimized model, low fidelity model:')\n",
    "print(m4)\n",
    "\n",
    "m4[\".*Gaussian_noise\"].unfix()\n",
    "m4[\".*Gaussian_noise\"].constrain_positive()\n",
    "m4.optimize_restarts(5, optimizer = \"bfgs\",  max_iters = 1000)\n",
    "mu4, var4 = m4.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' High fidelity model only '''\n",
    "k3 = GPy.kern.RBF(dim, ARD=True)\n",
    "m3 = GPy.models.GPRegression(X=X2_scaled, Y=Y2, kernel=k3)\n",
    "m3[\".*Gaussian_noise\"] = m3.Y.var()*0.001\n",
    "m3[\".*Gaussian_noise\"].fix()\n",
    "\n",
    "m3.optimize(max_iters = 500)\n",
    "print('*' * 80)\n",
    "print('Optimized model,  High fidelity:')\n",
    "print(m3)\n",
    "\n",
    "m3[\".*Gaussian_noise\"].unfix()\n",
    "m3[\".*Gaussian_noise\"].constrain_positive()\n",
    "m3.optimize_restarts(5, optimizer = \"bfgs\",  max_iters = 1000)\n",
    "mu3, var3 = m3.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.plot(Xtest[:,-1], mu3, 'r--', label='high fidelity (HF) predictive mean', linewidth = 1,zorder=3)\n",
    "ax.fill_between(Xtest[:,-1].flatten(), (mu3 + 2.0*np.sqrt(var3)).flatten(), (mu3 - 2.0*np.sqrt(var3)).flatten(), alpha=0.25, color='r',label='95% predictive intervals (HF)',zorder=3)\n",
    "ax.plot(tpts_HF, val_high_Y,'ro',fillstyle='none',label='HF validation data',zorder=3)\n",
    "ax.plot(Xtest[:,-1], mu4,'g--',label='low fidelity (LF) predictive mean', linewidth = 1,zorder=2)\n",
    "ax.fill_between(Xtest[:,-1].flatten(), (mu4 + 2.0*np.sqrt(var4)).flatten(), (mu4 - 2.0*np.sqrt(var4)).flatten(), alpha=0.25, color='g',label='95% predictive intervals (LF)',zorder=2)\n",
    "ax.plot(tpts_LF, val_low_Y,'go',fillstyle='none',label='LF validation data',zorder=2)\n",
    "ax.plot(Xtest[:,-1], mean, 'b--', label='multi-fidelity (MF) predictive mean', linewidth = 1,zorder=1)\n",
    "ax.fill_between(Xtest[:,-1].flatten(), (mean + 2.0*np.sqrt(var)).flatten(), (mean - 2.0*np.sqrt(var)).flatten(), alpha=0.25, color='b',label='95% predictive intervals (MF)',zorder=1)\n",
    "\n",
    "ax.set_ylim([0.5,2.0])\n",
    "ax.legend(frameon=True,bbox_to_anchor=(1.03,1.03),fontsize=20)\n",
    "ax.tick_params(axis='both', labelsize=20)\n",
    "ax.set_xlabel('Time [days]',fontsize=20)\n",
    "ax.set_ylabel(r'$\\theta^g_{max} [-]$',fontsize=20)\n",
    "ax.set_title('%s'%protocol,fontsize=20)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MFGPR-TE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
